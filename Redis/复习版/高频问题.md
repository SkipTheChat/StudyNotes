# 1 缓存

## 1.1 本地缓存和分布式缓存区别

**本地缓存**：本地缓存会占用堆内存，影响垃圾回收、影响系统性能。适用于数据不经常变动，但访问频次高，应用又耗时敏感的场景。但是本地缓存需要自己实现很多功能，如果实现的不好可能导致线程安全问题还有OOM问题。



**分布式缓存**：分布式缓存两大开销会导致其慢于本地缓存，网络延迟和对象序列化



## 1.2 如何设计本地缓存

### 1.2.1 数据结构

本地缓存最常见的是直接使用 Map 来存储，比如 guava 使用 ConcurrentHashMap，ehcache 也是用了 ConcurrentHashMap，Mybatis 二级缓存使用 HashMap 来存储：

```java
Map<Object, Object> cache = new ConcurrentHashMap<Object, Object>()
```

Mybatis 使用 HashMap 本身是非线程安全的，所以可以看到起内部使用了一个 SynchronizedCache 用来包装，保证线程的安全性；
 当然除了使用 Map 来存储，可能还使用其他数据结构来存储，比如 redis 使用了双端链表，压缩列表，整数集合，跳跃表和字典；当然这主要是因为 redis 对外提供的接口很丰富除了哈希还有列表，集合，有序集合等功能；



### 1.2.2 对象上限

本地缓存常见的一个属性，一般缓存都会有一个默认值比如 1024，在用户没有指定的情况下默认指定；当缓存的数据达到指定最大值时，需要有相关策略从缓存中清除多余的数据这就涉及到下面要介绍的清除策略；



### 1.2.3 清除策略

配合对象上限之后使用，场景的清除策略如：LRU(最近最少使用)、FIFO(先进先出)、LFU(最近最不常用)、SOFT(软引用)、WEAK(弱引用)；

1. **LRU**：Least Recently Used 的缩写最近最少使用，移除最长时间不被使用的对象；常见的使用 LinkedHashMap 来实现，也是很多本地缓存默认使用的策略；

2. **FIFO**：先进先出，按对象进入缓存的顺序来移除它们；常见使用队列 Queue 来实现；

3. **LFU**：Least Frequently Used 的缩写大概也是最近最少使用的意思，和 LRU 有点像；区别点在 LRU 的淘汰规则是基于访问时间，而 LFU 是基于访问次数的；可以通过 HashMap 并且记录访问次数来实现；

4. **SOFT**：软引用基于垃圾回收器状态和软引用规则移除对象；常见使用 SoftReference 来实现；

5. **WEAK**：弱引用更积极地基于垃圾收集器状态和弱引用规则移除对象；常见使用 WeakReference 来实现；

   



### 1.2.4 过期时间

设置过期时间，让缓存数据在指定时间过后自动删除；常见的过期数据删除策略有两种方式：被动删除和主动删除；
**被动删除**：每次进行 get/put 操作的时候都会检查一下当前 key 是否已经过期，如果过期则删除，类似如下代码：

```java
if (System.currentTimeMillis() - lastClear > clearInterval) {
      clear();
}
```



**主动删除**：专门有一个 job 在后台定期去检查数据是否过期，如果过期则删除，这其实可以有效的处理冷数据；





### 1.2.5 线程安全

尽量用线程安全的类去存储数据，比如使用 ConcurrentHashMap 代替 HashMap；或者提供相应的同步处理类，比如 Mybatis 提供了 SynchronizedCache：

```java
public synchronized void putObject(Object key, Object object) {
    ...省略...
  }

  @Override
  public synchronized Object getObject(Object key) {
    ...省略...
  }
```



### 1.2.6 简明的接口

提供常用的 get，put，remove，clear，getSize 方法即可，比如 Mybatis 的 Cache 接口：

```java
public interface Cache {
  String getId();
  void putObject(Object key, Object value);
  Object getObject(Object key);
  Object removeObject(Object key);
  void clear();
  int getSize();
  ReadWriteLock getReadWriteLock();
}
```



再来看看 guava 提供的 Cache 接口，相对来说也是比较简洁的：

```java
public interface Cache<K, V> {
  V getIfPresent(@CompatibleWith("K") Object key);
  V get(K key, Callable<? extends V> loader) throws ExecutionException;
  ImmutableMap<K, V> getAllPresent(Iterable<?> keys);
  void put(K key, V value);
  void putAll(Map<? extends K, ? extends V> m);
  void invalidate(@CompatibleWith("K") Object key);
  void invalidateAll(Iterable<?> keys);
  void invalidateAll();
  long size();
  CacheStats stats();
  ConcurrentMap<K, V> asMap();
  void cleanUp();
}
```



### 1.2.7 是否持久化

持久化的好处是重启之后可以再次加载文件中的数据，这样就起到类似热加载的功效；比如redis提供了 AOF 和 RDB 两种持久化方式；当然很多情况下可以配合使用两种方式；



### 1.2.8 阻塞机制

除了在 Mybatis 中看到了 BlockingCache 来实现此功能，之前在看的时候其中有实现一个很完美的缓存，大致代码如下：

```java
public class Memoizerl<A, V> implements Computable<A, V> {
    private final Map<A, Future<V>> cache = new ConcurrentHashMap<A, Future<V>>();
    private final Computable<A, V> c;

    public Memoizerl(Computable<A, V> c) {
        this.c = c;
    }

    @Override
    public V compute(A arg) throws InterruptedException, ExecutionException {
        while (true) {
            Future<V> f = cache.get(arg);
            if (f == null) {
                Callable<V> eval = new Callable<V>() {
                    @Override
                    public V call() throws Exception {
                        return c.compute(arg);
                    }
                };
                FutureTask<V> ft = new FutureTask<V>(eval);
                f = cache.putIfAbsent(arg, ft);
                if (f == null) {
                    f = ft;
                    ft.run();
                }
                try {
                    return f.get();
                } catch (CancellationException e) {
                    cache.remove(arg, f);
                }
            }
        }
    }
}
```

compute  是一个计算很费时的方法，所以这里把计算的结果缓存起来，但是有个问题就是如果两个线程同时进入此方法中怎么保证只计算一次，这里最核心的地方在于使用了  ConcurrentHashMap 的 putIfAbsent 方法，同时只会写入一个 FutureTask； 





# 2 如何保证缓存和数据库的数据一致性

只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题

那么，如何解决一致性问题？

一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，最好不要做这个方案。它会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上请求。



## 2.1 Cache Aside Pattern

最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。

- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
- 更新的时候，先删除缓存，再更新数据库



### 2.1.1 **更新的时候为什么是删除缓存，而不是更新缓存？**

1. 在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。
2. **lazy 计算**的思想，让它到需要被使用的时候再重新计算。因为更新缓存的代价有时候是很高的，如果频繁修改一个缓存涉及的多个表，缓存也频繁更新，但是缓存并不一定会被读到，这样浪费了资源。像 mybatis，hibernate，都有懒加载思想。





### 2.1.2 为什么更新的时候，先删除缓存，再更新数据库？

> 问题：先修改数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。

**解决思路**：先删除缓存，再修改数据库。如果数据库修改失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。

解决了最初级的数据不一致问题。



### 2.1.3 **比较复杂的数据不一致问题分析**

> 问题：数据发生了变更，先删除了缓存，然后要去修改数据库，还没来得及修改，一个请求过来，去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中。随后数据变更的程序完成了数据库的修改。

高并发场景下，会很容易出现这样的问题。



**解决方案如下：**

为解决其缺陷，添加队列，凡是遇到写请求，则将写请求放入队列中，由队列对写请求统一管理，写请求处理成功，则从队列中删除。当有一个读请求过来时，到队列查询，是否有对应的写请求，如果有则放入队列中，等待写请求执行完之后再执行读请求。这样使得请求遵循了FIFO，也就解决了数据不一致的问题。



高并发的场景下，该解决方案要注意的问题：



**1.读请求长时阻塞**

倘若访问量大，处理器来不及处理，队列内的请求数量越来越高，则会影响查询效率。出现这种情况，就要进行压力测试，加机器集群执行，帮忙分担压力，为防止某个请求阻塞情况，也可为其设置超时机制或者过期机制。



**2、读请求并发量过高**

这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值。

但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。



**3、多服务实例部署的请求路由**

可能这个服务部署了多个实例，那么必须保证说，执行数据更新操作，以及执行缓存更新操作的请求，都通过 Nginx 服务器路由到相同的服务实例上。

比如说，对同一个商品的读写请求，全部路由到同一台机器上。可以自己去做服务间的按照某个请求参数的 hash 路由，也可以用 Nginx 的 hash 路由功能等等。



**4、热点商品的路由问题，导致请求的倾斜**

万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。



 

# 3 两阶段提交&三阶段提交

关于分布式事务的提交分为两阶段提交和三阶段提交

[博客](https://www.cnblogs.com/heliusKing/p/12122145.html)

## 3.1 2PC

2PC即两阶段提交协议，P是指准备阶段，C是指提交阶段。

整个事务过程由事务管理器和参与者组成，事务管理器负责 决策整个分布式事务的提交和回滚，事务参与者负责自己本地事务的提交和回滚。

在计算机中部分关系数据库如Oracle、MySQL支持两阶段提交协议，如下图：

1. 准备阶段（Prepare phase）：事务管理器给每个参与者发送Prepare消息，每个数据库参与者在本地执行事  务，并写本地的Undo/Redo日志，此时事务没有提交。  （Undo日志是记录修改前的数据，用于数据库回滚，Redo日志是记录修改后的数据，用于提交事务后写入数 据文件）

2. 提交阶段（commit phase）：如果事务管理器收到了参与者的执行失败或者超时消息时，直接给每个参与者  发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据事务管理器的指令执行提交或者回滚操  作，并释放事务处理过程中使用的锁资源。注意:必须在最后阶段释放锁资源。 下图展示了2PC的两个阶段，分成功和失败两个情况说明：

   **成功情况：**

[![img](https://img2018.cnblogs.com/blog/1005988/201912/1005988-20191230230132277-2118061777.png)](https://img2018.cnblogs.com/blog/1005988/201912/1005988-20191230230132277-2118061777.png)

**失败情况**

[![img](https://img2018.cnblogs.com/blog/1005988/201912/1005988-20191230230144578-1462186490.png)](https://img2018.cnblogs.com/blog/1005988/201912/1005988-20191230230144578-1462186490.png)

- 阶段一 提交事务请求

1. 协调者向所有的参与者节点发送事务内容，询问是否可以执行事务操作，并等待其他参与者节点的
    反馈
2. 参与者节点收到协调者的事务操作后，执行操作，但不提交
3. 各参与者节点反馈给协调者，事务是否可以执行

- 阶段二 事务提交

根据一阶段各个参与者节点反馈的ack,如果所有参与者节点反馈ack，则执行事务提交，否则中断事务
 事务提交：

1. 协调者向各个参与者节点发送commit请求
2. 参与者节点接受到commit请求后，执行事务的提交操作
3. 各参与者节点完成事务提交后，向协调者返送提交commit成功确认消息
4. 协调者接受各个参与者节点的ack后，完成事务commit



**中断事务：**
 1、发送回滚请求
 2、各个参与者节点回滚事务
 3、反馈给协调者事务回滚结果
 4、协调者接受各参与者节点ack后回滚事务



**二阶段提交存在的问题：**

- 同步阻塞
   二阶段提交过程中，所有参与事务操作的节点处于同步阻塞状态，无法进行其他的操作
- 单点问题
   参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）
- 脑裂导致数据不一致
   如果分布式节点出现网络分区，某些参与者未收到commit提交命令。则出现部分参与者完成数据提
   交。未收到commit的命令的参与者则无法进行事务提交，整个分布式系统便出现了数据不一致性现
   象。



## 3.2 3PC

3PC是2PC的改进版，实质是将2PC中提交事务请求拆分为两步，形成了**CanCommit**、**PreCommit**、
 **doCommit**三个阶段的事务一致性协议

[![img](https://img2018.cnblogs.com/blog/1005988/201912/1005988-20191230230206869-1128696255.png)](https://img2018.cnblogs.com/blog/1005988/201912/1005988-20191230230206869-1128696255.png)

**阶段一 : CanCommit**
 1、事务询问
 2、各参与者节点向协调者反馈事务询问的响应
 **阶段二 : PreCommit**
 根据阶段一的反馈结果分为两种情况

1. 执行事务预提交
   1. 发送预提交请求
       协调者向所有参与者节点发送preCommit请求，进入prepared阶段
   2. 事务预提交
       各参与者节点接受到preCommit请求后，执行事务操作
   3. 各参与者节点向协调者反馈事务执行
2. **中断事务**
    任意一个参与者节点反馈给协调者**响应No**时，或者在**等待超时**（**协调者等待参与者**）后，协调者还未收到参与者的反
    馈，就中断事务，中断事务分为两步：
    1）协调者向各个参与者节点发送abort请求
    2）参与者收到abort请求，或者等待超时时间后，中断事务(**参与者等待协调者**)

**阶段三 : doCommit**
 1、执行提交

- 发送提交请求
   协调者向所有参与者节点发送doCommit请求
- 事务提交
   各参与者节点接受到doCommit请求后，执行事务提交操作
- 反馈事务提交结果
- 事务完成
   协调者接受各个参与者反馈的ack后，完成事务

2、中断事务

1. 参与者接受到abort请求后，执行事务回滚
2. 参与者完成事务回滚以后，向协调者发送ack
3. 协调者接受回滚ack后，回滚事务



**3PC相较于2PC而言，解决了协调者挂点后参与者无限阻塞和单点问题，但是仍然无法解决网络分**
 **区问题**


