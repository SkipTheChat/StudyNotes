# 1 缓存

## 1.1 本地缓存和分布式缓存区别

**本地缓存**：本地缓存会占用堆内存，影响垃圾回收、影响系统性能。适用于数据不经常变动，但访问频次高，应用又耗时敏感的场景。但是本地缓存需要自己实现很多功能，如果实现的不好可能导致线程安全问题还有OOM问题。



**分布式缓存**：分布式缓存两大开销会导致其慢于本地缓存，网络延迟和对象序列化



## 1.2 如何设计本地缓存

### 1.2.1 数据结构

本地缓存最常见的是直接使用 Map 来存储，比如 guava 使用 ConcurrentHashMap，ehcache 也是用了 ConcurrentHashMap，Mybatis 二级缓存使用 HashMap 来存储：

```java
Map<Object, Object> cache = new ConcurrentHashMap<Object, Object>()
```

Mybatis 使用 HashMap 本身是非线程安全的，所以可以看到起内部使用了一个 SynchronizedCache 用来包装，保证线程的安全性；
 当然除了使用 Map 来存储，可能还使用其他数据结构来存储，比如 redis 使用了双端链表，压缩列表，整数集合，跳跃表和字典；当然这主要是因为 redis 对外提供的接口很丰富除了哈希还有列表，集合，有序集合等功能；



### 1.2.2 对象上限

本地缓存常见的一个属性，一般缓存都会有一个默认值比如 1024，在用户没有指定的情况下默认指定；当缓存的数据达到指定最大值时，需要有相关策略从缓存中清除多余的数据这就涉及到下面要介绍的清除策略；



### 1.2.3 清除策略

配合对象上限之后使用，场景的清除策略如：LRU(最近最少使用)、FIFO(先进先出)、LFU(最近最不常用)、SOFT(软引用)、WEAK(弱引用)；

1. **LRU**：Least Recently Used 的缩写最近最少使用，移除最长时间不被使用的对象；常见的使用 LinkedHashMap 来实现，也是很多本地缓存默认使用的策略；

2. **FIFO**：先进先出，按对象进入缓存的顺序来移除它们；常见使用队列 Queue 来实现；

3. **LFU**：Least Frequently Used 的缩写大概也是最近最少使用的意思，和 LRU 有点像；区别点在 LRU 的淘汰规则是基于访问时间，而 LFU 是基于访问次数的；可以通过 HashMap 并且记录访问次数来实现；

4. **SOFT**：软引用基于垃圾回收器状态和软引用规则移除对象；常见使用 SoftReference 来实现；

5. **WEAK**：弱引用更积极地基于垃圾收集器状态和弱引用规则移除对象；常见使用 WeakReference 来实现；

   



### 1.2.4 过期时间

设置过期时间，让缓存数据在指定时间过后自动删除；常见的过期数据删除策略有两种方式：被动删除和主动删除；
**被动删除**：每次进行 get/put 操作的时候都会检查一下当前 key 是否已经过期，如果过期则删除，类似如下代码：

```java
if (System.currentTimeMillis() - lastClear > clearInterval) {
      clear();
}
```



**主动删除**：专门有一个 job 在后台定期去检查数据是否过期，如果过期则删除，这其实可以有效的处理冷数据；





### 1.2.5 线程安全

尽量用线程安全的类去存储数据，比如使用 ConcurrentHashMap 代替 HashMap；或者提供相应的同步处理类，比如 Mybatis 提供了 SynchronizedCache：

```java
public synchronized void putObject(Object key, Object object) {
    ...省略...
  }

  @Override
  public synchronized Object getObject(Object key) {
    ...省略...
  }
```



### 1.2.6 简明的接口

提供常用的 get，put，remove，clear，getSize 方法即可，比如 Mybatis 的 Cache 接口：

```java
public interface Cache {
  String getId();
  void putObject(Object key, Object value);
  Object getObject(Object key);
  Object removeObject(Object key);
  void clear();
  int getSize();
  ReadWriteLock getReadWriteLock();
}
```



再来看看 guava 提供的 Cache 接口，相对来说也是比较简洁的：

```java
public interface Cache<K, V> {
  V getIfPresent(@CompatibleWith("K") Object key);
  V get(K key, Callable<? extends V> loader) throws ExecutionException;
  ImmutableMap<K, V> getAllPresent(Iterable<?> keys);
  void put(K key, V value);
  void putAll(Map<? extends K, ? extends V> m);
  void invalidate(@CompatibleWith("K") Object key);
  void invalidateAll(Iterable<?> keys);
  void invalidateAll();
  long size();
  CacheStats stats();
  ConcurrentMap<K, V> asMap();
  void cleanUp();
}
```



### 1.2.7 是否持久化

持久化的好处是重启之后可以再次加载文件中的数据，这样就起到类似热加载的功效；比如redis提供了 AOF 和 RDB 两种持久化方式；当然很多情况下可以配合使用两种方式；



### 1.2.8 阻塞机制

除了在 Mybatis 中看到了 BlockingCache 来实现此功能，之前在看的时候其中有实现一个很完美的缓存，大致代码如下：

```java
public class Memoizerl<A, V> implements Computable<A, V> {
    private final Map<A, Future<V>> cache = new ConcurrentHashMap<A, Future<V>>();
    private final Computable<A, V> c;

    public Memoizerl(Computable<A, V> c) {
        this.c = c;
    }

    @Override
    public V compute(A arg) throws InterruptedException, ExecutionException {
        while (true) {
            Future<V> f = cache.get(arg);
            if (f == null) {
                Callable<V> eval = new Callable<V>() {
                    @Override
                    public V call() throws Exception {
                        return c.compute(arg);
                    }
                };
                FutureTask<V> ft = new FutureTask<V>(eval);
                f = cache.putIfAbsent(arg, ft);
                if (f == null) {
                    f = ft;
                    ft.run();
                }
                try {
                    return f.get();
                } catch (CancellationException e) {
                    cache.remove(arg, f);
                }
            }
        }
    }
}
```

compute  是一个计算很费时的方法，所以这里把计算的结果缓存起来，但是有个问题就是如果两个线程同时进入此方法中怎么保证只计算一次，这里最核心的地方在于使用了  ConcurrentHashMap 的 putIfAbsent 方法，同时只会写入一个 FutureTask； 





# 2 如何保证缓存和数据库的数据一致性

只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问题

那么，如何解决一致性问题？

一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，最好不要做这个方案。它会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上请求。



## 2.1 Cache Aside Pattern

最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。

- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
- 更新的时候，先删除缓存，再更新数据库



### 2.1.1 **更新的时候为什么是删除缓存，而不是更新缓存？**

1. 在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。
2. **lazy 计算**的思想，让它到需要被使用的时候再重新计算。因为更新缓存的代价有时候是很高的，如果频繁修改一个缓存涉及的多个表，缓存也频繁更新，但是缓存并不一定会被读到，这样浪费了资源。像 mybatis，hibernate，都有懒加载思想。





### 2.1.2 为什么更新的时候，先删除缓存，再更新数据库？

> 问题：先修改数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。

**解决思路**：先删除缓存，再修改数据库。如果数据库修改失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。

解决了最初级的数据不一致问题。



### 2.1.3 **比较复杂的数据不一致问题分析**

> 问题：数据发生了变更，先删除了缓存，然后要去修改数据库，还没来得及修改，一个请求过来，去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中。随后数据变更的程序完成了数据库的修改。

高并发场景下，会很容易出现这样的问题。



**解决方案如下：**

为解决其缺陷，添加队列，凡是遇到写请求，则将写请求放入队列中，由队列对写请求统一管理，写请求处理成功，则从队列中删除。当有一个读请求过来时，到队列查询，是否有对应的写请求，如果有则放入队列中，等待写请求执行完之后再执行读请求。这样使得请求遵循了FIFO，也就解决了数据不一致的问题。



高并发的场景下，该解决方案要注意的问题：



**1.读请求长时阻塞**

倘若访问量大，处理器来不及处理，队列内的请求数量越来越高，则会影响查询效率。出现这种情况，就要进行压力测试，加机器集群执行，帮忙分担压力，为防止某个请求阻塞情况，也可为其设置超时机制或者过期机制。



**2、读请求并发量过高**

这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时 hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰值。

但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。



**3、多服务实例部署的请求路由**

可能这个服务部署了多个实例，那么必须保证说，执行数据更新操作，以及执行缓存更新操作的请求，都通过 Nginx 服务器路由到相同的服务实例上。

比如说，对同一个商品的读写请求，全部路由到同一台机器上。可以自己去做服务间的按照某个请求参数的 hash 路由，也可以用 Nginx 的 hash 路由功能等等。



**4、热点商品的路由问题，导致请求的倾斜**

万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的压力过大。



 

# 3 两阶段提交&三阶段提交

关于分布式事务的提交分为两阶段提交和三阶段提交

[博客](https://www.cnblogs.com/heliusKing/p/12122145.html)

## 3.1 2PC

2PC即两阶段提交协议，P是指准备阶段，C是指提交阶段。

整个事务过程由事务管理器和参与者组成，事务管理器负责 决策整个分布式事务的提交和回滚，事务参与者负责自己本地事务的提交和回滚。

在计算机中部分关系数据库如Oracle、MySQL支持两阶段提交协议，如下图：

1. 准备阶段（Prepare phase）：事务管理器给每个参与者发送Prepare消息，每个数据库参与者在本地执行事  务，并写本地的Undo/Redo日志，此时事务没有提交。  （Undo日志是记录修改前的数据，用于数据库回滚，Redo日志是记录修改后的数据，用于提交事务后写入数 据文件）

2. 提交阶段（commit phase）：如果事务管理器收到了参与者的执行失败或者超时消息时，直接给每个参与者  发送回滚(Rollback)消息；否则，发送提交(Commit)消息；参与者根据事务管理器的指令执行提交或者回滚操  作，并释放事务处理过程中使用的锁资源。注意:必须在最后阶段释放锁资源。 下图展示了2PC的两个阶段，分成功和失败两个情况说明：

   **成功情况：**

[![img](https://img2018.cnblogs.com/blog/1005988/201912/1005988-20191230230132277-2118061777.png)](https://img2018.cnblogs.com/blog/1005988/201912/1005988-20191230230132277-2118061777.png)

**失败情况**

[![img](https://img2018.cnblogs.com/blog/1005988/201912/1005988-20191230230144578-1462186490.png)](https://img2018.cnblogs.com/blog/1005988/201912/1005988-20191230230144578-1462186490.png)

- 阶段一 提交事务请求

1. 协调者向所有的参与者节点发送事务内容，询问是否可以执行事务操作，并等待其他参与者节点的
    反馈
2. 参与者节点收到协调者的事务操作后，执行操作，但不提交
3. 各参与者节点反馈给协调者，事务是否可以执行

- 阶段二 事务提交

根据一阶段各个参与者节点反馈的ack,如果所有参与者节点反馈ack，则执行事务提交，否则中断事务
 事务提交：

1. 协调者向各个参与者节点发送commit请求
2. 参与者节点接受到commit请求后，执行事务的提交操作
3. 各参与者节点完成事务提交后，向协调者返送提交commit成功确认消息
4. 协调者接受各个参与者节点的ack后，完成事务commit



**中断事务：**
 1、发送回滚请求
 2、各个参与者节点回滚事务
 3、反馈给协调者事务回滚结果
 4、协调者接受各参与者节点ack后回滚事务



**二阶段提交存在的问题：**

- 同步阻塞
   二阶段提交过程中，所有参与事务操作的节点处于同步阻塞状态，无法进行其他的操作
- 单点问题
   参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作。（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）
- 脑裂导致数据不一致
   如果分布式节点出现网络分区，某些参与者未收到commit提交命令。则出现部分参与者完成数据提
   交。未收到commit的命令的参与者则无法进行事务提交，整个分布式系统便出现了数据不一致性现
   象。



## 3.2 3PC

3PC是2PC的改进版，实质是将2PC中提交事务请求拆分为两步，形成了**CanCommit**、**PreCommit**、
 **doCommit**三个阶段的事务一致性协议

[![img](https://img2018.cnblogs.com/blog/1005988/201912/1005988-20191230230206869-1128696255.png)](https://img2018.cnblogs.com/blog/1005988/201912/1005988-20191230230206869-1128696255.png)

**阶段一 : CanCommit**
 1、事务询问
 2、各参与者节点向协调者反馈事务询问的响应
 **阶段二 : PreCommit**
 根据阶段一的反馈结果分为两种情况

1. 执行事务预提交
   1. 发送预提交请求
       协调者向所有参与者节点发送preCommit请求，进入prepared阶段
   2. 事务预提交
       各参与者节点接受到preCommit请求后，执行事务操作
   3. 各参与者节点向协调者反馈事务执行
2. **中断事务**
    任意一个参与者节点反馈给协调者**响应No**时，或者在**等待超时**（**协调者等待参与者**）后，协调者还未收到参与者的反
    馈，就中断事务，中断事务分为两步：
    1）协调者向各个参与者节点发送abort请求
    2）参与者收到abort请求，或者等待超时时间后，中断事务(**参与者等待协调者**)

**阶段三 : doCommit**
 1、执行提交

- 发送提交请求
   协调者向所有参与者节点发送doCommit请求
- 事务提交
   各参与者节点接受到doCommit请求后，执行事务提交操作
- 反馈事务提交结果
- 事务完成
   协调者接受各个参与者反馈的ack后，完成事务

2、中断事务

1. 参与者接受到abort请求后，执行事务回滚
2. 参与者完成事务回滚以后，向协调者发送ack
3. 协调者接受回滚ack后，回滚事务



**3PC相较于2PC而言，解决了协调者挂点后参与者无限阻塞和单点问题，但是仍然无法解决网络分**
 **区问题**





# 4 redis为什么快

1. 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；

2. 数据结构简单，Redis的数据结构比较简单，是为Redis专门设计的，而这些简单的数据结构的查找和操作的时间复杂度都是O(1)

3. 采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；

4. 使用多路I/O复用模型，非阻塞IO；

5. 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

> 以上几点都比较好理解，下边我们针对多路 I/O 复用模型进行简单的探讨：

> 多路 I/O 复用模型

多路I/O复用模型是利用  select、poll、epoll 可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 I/O  事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll  是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。

这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快，也就是说内存内的操作不会成为影响Redis性能的瓶颈，主要由以上几点造就了 Redis 具有很高的吞吐量。



# 5 大key问题

> 如果有个value的大小是2M会有什么问题？

bigkey 通常会导致内存空间不平衡，超时阻塞，如果 key 较大，redis  又是单线程，操作 bigkey 比较耗时，那么阻塞 redis 的可能性增大。每次获取 bigKey 的网络流量较大，假设一个 bigkey 为 2MB,每秒访问量为 2000，那么每秒产生 2000MB 的流量，对于普通千兆网卡，按照字节算 128M/S  的服务器来说可能扛不住。而且一般服务器采用单机多实例方式来部署，所以还可能对其他实例造成影响。

1. 如果是集群模式下，无法做到负载均衡，导致请求倾斜到某个实例上，而这个实例的QPS会比较大，内存占用也较多；对于Redis单线程模型又容易出现CPU瓶颈，当内存出现瓶颈时，只能进行纵向库容，使用更牛逼的服务器。
2. 涉及到大key的操作，尤其是使用hgetall、lrange、get、hmget  等操作时，网卡可能会成为瓶颈，也会到导致堵塞其它操作，qps  就有可能出现突降或者突升的情况，趋势上看起来十分不平滑，严重时会导致应用程序连不上，实例或者集群在某些时间段内不可用的状态。
3. 假如这个key需要进行删除操作，如果直接进行DEL 操作，被操作的实例会被Block住，导致无法响应应用的请求，而这个Block的时间会随着key的变大而变长。



> 最大支持的value大小是多少？

redis的key和string类型value限制均为512MB



# 6 redis是单线程还是多线程

不同版本的Redis是不同的，在Redis4.0之前，Redis是单线程运行的，但单线程并不代表效率低，像Nginx、Nodejs也是单线程程序，但是它们的效率并不低。

原因是Redis是基于内存的，它的瓶颈在于机器的内存、网络带宽，而不是CPU，在CPU还没达到瓶颈时机器内存可能就满了、或者带宽达到瓶颈了。因此CPU不是主要原因，那么自然就采用单线程了，况且使用多线程比较麻烦。

但是在Redis4.0的时候，已经开始支持多线程了，比如后台删除等功能。

> 简单来说，Redis在4.0之前使用单线程的模式是因为以下三个原因

1. 使用单线程模式的Redis，其开发和维护更简单，因为单线程模式方便开发和调试。

2.  单线程指的是网络请求模块使用了一个线程（所以不需考虑并发安全性），即一个线程处理所有网络请求，主要是因为Redis内部使用了基于epoll的多路复用，所以即使使用单线程模型也能够并发地处理多客户端的请求

3. 对于Redis来说，主要的性能瓶颈是内存或网络带宽，而非CPU

> 惰性删除（异步删除）

但Redis在4.0以及之后的版本中引入了惰性删除（也叫异步删除），意思就是我们可以使用异步的方式对Redis中的数据进行删除操作，例如：

1.unlink key：和del key类似，删除指定的key，若key不存在则key被跳过。但是del会产生阻塞，而unlink命令会在另一个线程中回收内存，会在另一个线程中回收内存，因此它是非阻塞的。 这也是该命令名字的由来：仅将keys从keyspace元数据中删除，真正的删除会在后续异步操作。

2.flushdb async：删除当前数据库的所有数据

3.flushall async：删除所有库中的数据

这样处理的好处是不会使Redis的主线程卡顿，会把这些操作交给后台线程来执行。

通常情况下使用del指令可以很快的删除数据，但是当被删除的key是一个非常大的对象时，例如：删除的时包含成千上万个元素的hash集合时，那么del指令就会造成Redis主线程卡顿，因此使用惰性删除可以有效避免Redis卡顿问题。





# 7 redis的多线程

Redis单线程的优点非常，不但降低了Redis内部实现的负责性，也让所有操作都可以在无锁的情况下进行，并且不存在死锁和线程切换带来的性能以及时间上的消耗；但是其缺点也很明显，单线程机制导致Redis的QPS（Query Per Second，每秒查询数）很难得到有效的提高（虽然够快了，但人毕竟还是要有更高的追求的）。

Redis在4.0版本中虽然引入了多线程，但是此版本的多线程**只能用于大数据量的异步删除，对于非删除操作的意义并不是很大**。

如果我们使用Redis多线程就可以分摊Redis同步读写IO的压力，以及充分利用多核CPU资源，并且可以有效的提升Redis的QPS。在Redis中虽然使用了IO多路复用，并且是基于非阻塞的IO进行操作的，但是IO的读写本身是阻塞的。比如当socket中有数据时，Redis会先将数据从内核态空间拷贝到用户态空间，然后再进行相关操作，而这个拷贝过程是阻塞的，并且当数据量越大时拷贝所需要的的时间就越多，而这些操作都是基于单线程完成的。

因此在Redis6.0中**新增了多线程的功能来提高IO的读写性能**，它的主要实现思路是将主线程的IO读写任务拆分给一组独立的线程去执行，这样就可以使用多个socket的读写并行化了，但Redis的命令依旧是主线程串行执行的。

> 注意：Redis6.0是默认禁用多线程的，但可以通过配置文件redis.conf中的io-threads-do-reads 等于 true 来开启。但是还不够，除此之外我们还需要设置线程的数量才能正确地开启多线程的功能，同样是修改Redis的配置，例如设置 io-threads 4，表示开启4个线程。



# 8 