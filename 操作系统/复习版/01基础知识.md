# 1 进程与线程的区别

1. 进程是资源的分配和调度的一个独立单元，而线程是CPU调度的基本单元
2. 同一个进程中可以包括多个线程，并且线程共享整个进程的资源（寄存器、堆栈、上下文），一个进行至少包3.进程的创建调用fork或者vfork，而线程的创建调用pthread_create，进程结束后它拥有的所有线程都将销毁，而线程的结束不会影响同个进程中的其他线程的结束
3. 线程是轻两级的进程，它的创建和销毁所需要的时间比进程小很多，所有操作系统中的执行功能都是创建线程去完成的
4. 线程中执行时一般都要进行同步和互斥，因为他们共享同一进程的所有资源
5. 线程有自己的私有属性TCB，线程id，寄存器、硬件上下文，而进程也有自己的私有属性进程控制块PCB，这些私有属性是不被共享的，用来标示一个进程或一个线程的标志

进程和线程的主要差别在于它们是不同的操作系统资源管理方式。 



**共享的资源有：**

1. 堆：由于堆是在进程空间中开辟出来的，所以它是理所当然地被共享的；因此new出来的都是共享的（16位平台上分全局堆和局部堆，局部堆是独享的）

2. 全局变量 它是与具体某一函数无关的，所以也与特定线程无关；因此也是共享的
3. 静态变量 虽然对于局部变量来说，它在代码中是“放”在某一函数中的，但是其存放位置和全局变量一样，存于堆中开辟的.bss和.data段，是共享的
4. 文件等公用资源  这个是共享的，使用这些公共资源的线程必须同步。Win32 提供了几种同步资源的方式，包括信号、临界区、事件和互斥体。

**独享的资源有：**

1. 栈：栈是独享的
2. 寄存器 ：这个可能会误解，因为电脑的寄存器是物理的，每个线程去取值难道不一样吗？其实线程里存放的是副本，包括程序计数器PC





# 2 fork

[博客1](https://blog.csdn.net/jason314/article/details/5640969)

[博客2](https://www.jianshu.com/p/1327c51a4a99)

一个进程，包括代码、数据和分配给进程的资源。fork（）函数通过系统调用创建一个与原来进程几乎完全相同的进程，也就是两个进程可以做完全相同的事，但如果初始参数或者传入的变量不同，两个进程也可以做不同的事。 

一个进程调用fork（）函数后，系统先给新的进程分配资源，例如存储数据和代码的空间。然后把原来的进程的所有值都复制到新的新进程中，只有少数值与原来的进程的值不同。相当于克隆了一个自己。





# 3 进程间的通信方式（IPC）

> InterProcess Communication 

**共享内存是最快的 IPC 方式** 

### 3.1 管道

**管道（pipe）**：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有血缘关系的进程间使用。进程的血缘关系通常指父子进程关系。管道分为 pipe（无名管道）和 fifo（命名管道）两种，有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间通信。

无名管道&有名管道区别：无名管道主要用于有血缘关系的两个进程间通信，是内核使用环形队列机制实现，借助内核缓冲区实现的。

有名管道主要用于两个不相干的进程间通信，我认为之所以叫有名管道是因为他们借助mkfifo（）函数创建的伪文件利用内核缓冲区进行通信，因为创建文件可以指定文件名所以操作和使用文件几乎一样。

**pipe原理：**

具有固定的读端和写端，它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）。

它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。

```c
#include <unistd.h>
int pipe(int fd[2]);    // 返回值：若成功返回0，失败返回-1
```

当一个管道建立时，它会创建两个文件描述符：`fd[0]`为读而打开，`fd[1]`为写而打开。如下图： 

![](D:/Jessica(note)/Marie(2019)/programming/08%E6%80%BB%E7%AC%94%E8%AE%B0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/assets/1.3.png)

要关闭管道只需将这两个文件描述符关闭即可。 



 **例子**

单个进程中的管道几乎没有任何用处。所以，通常调用 pipe 的进程接着调用 fork，这样就创建了父进程与子进程之间的 IPC 通道。如下图所示： **右图就是无名管道pipe的实现原理**

![](D:/Jessica(note)/Marie(2019)/programming/08%E6%80%BB%E7%AC%94%E8%AE%B0/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/assets/1.4.png)

若要数据流从父进程流向子进程，则关闭父进程的读端（`fd[0]`）与子进程的写端（`fd[1]`）；反之，则可以使数据流从子进程流向父进程。 







### 3.2**信号量（semophore）**

信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它通常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。



### 3.3 **消息队列（message queue）**

**消息队列是由消息组成的链表**，存放在内核中   并由消息队列标识符标识。**消息队列提供了一个从一个进程向另一个进程发送数据块的方法，每个数据块都可以被认为是有一个类型**，接受者接受的数据块可以有不同的类型。   但是同管道类似，它有一个不足就是每个消息的最大长度是有上限的。

特点：

- 生命周期随内核，消息队列会一直存在，需要我们显示的调用接口删除或使用命令删除
- 消息队列可以双向通信
- 克服了管道只能承载无格式字节流的缺点



### 3.4 **信号（signal）**

信号可以直接进行用户空间进程和内核进程之间的交互，内核进程也可以利用它来通知用户空间进程发生了哪些系统事件。如果该进程当前并未处于执行态，则该信号就由内核保存起来，直到该进程恢复执行再传递给它；如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被 取消时才被传递给进程。



### 3.5**共享内存（shared memory）**

共享内存（Shared Memory），指两个或多个进程共享一个给定的存储区。

特点：

1. 共享内存是最快的一种 IPC，因为进程是直接对内存进行存取。
2. 因为多个进程可以同时操作，所以需要进行同步。
3. 信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问



### 3.6 **套接字（socket）**

socket，即套接字是一种通信机制，凭借这种机制，客户/服务器（即要进行通信的进程）系统的开发工作既可以在本地单机上进行，也可以跨网络进行。





# 4 线程同步的方式

### 4.1 linux线程同步机制

[博客](https://blog.csdn.net/a987073381/article/details/52029070)

1、锁机制

- 互斥锁：提供了以排它方式阻止数据结构被并发修改的方法。
- 读写锁：允许多个线程同时读共享数据，而对写操作互斥。
- 条件变量：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。

2、信号量机制：包括无名线程信号量与有名线程信号量

3、信号机制：类似于进程间的信号处理。

线程间通信的主要目的是用于线程同步，所以线程没有象进程通信中用于数据交换的通信机制。





### 4.2 java线程同步机制

[博客](https://blog.csdn.net/qq_22847457/article/details/89430008)

##### 4.2.1 synchronized关键字  

由于java的每个对象都有一个内置锁，当用此关键字修饰方法时， 内置锁会保护整个方法。在调用该方法前，需要获得内置锁，否则就处于阻塞状态。

>注： synchronized关键字也可以修饰静态方法，此时如果调用该静态方法，将会锁住整个类。
>
>sychronized修饰的方法可以是静态方法和非静态方法，但是不能是抽象类的抽象方法，也不能是接口中的接口方法。



##### 4.2.2 wait和notify 

wait():使一个线程处于等待状态，并且释放所持有的对象的lock。

sleep():使一个正在运行的线程处于睡眠状态，是一个静态方法，调用此方法要捕捉InterruptedException异常。
notify():唤醒一个处于等待状态的线程，注意的是在调用此方法的时候，并不能确切的唤醒某一个等待状态的线程，而是由JVM确定唤醒哪个线程，而且不是按优先级。
Allnotity():唤醒所有处入等待状态的线程，注意并不是给所有唤醒线程一个对象的锁，而是让它们竞争。


##### 4.2.3 volatile

1. volatile关键字为域变量的访问提供了一种免锁机制
2. 使用volatile修饰域相当于告诉虚拟机该域可能会被其他线程更新
3. 因此每次使用该域就要重新计算，而不是使用寄存器中的值 
4. volatile不会提供任何原子操作，它也不能用来修饰final类型的变量 



##### 4.2.4 ReentrantLock

在JavaSE5.0中新增了一个java.util.concurrent包来支持同步。 ReentrantLock类是可重入、互斥、实现了Lock接口的锁，它与使用synchronized方法和快具有相同的基本行为和语义，并且扩展了其能力。

 ReenreantLock类的常用方法有：

- ReentrantLock() : 创建一个ReentrantLock实例 
- lock() : 获得锁 
- unlock() : 释放锁 

> 注：ReentrantLock()还有一个可以创建公平锁的构造方法，但由于能大幅度降低程序运行效率，不推荐使用  



##### 4.2.5 ThreadLocal

如果使用ThreadLocal管理变量，则每一个使用该变量的线程都获得该变量的副本，副本之间相互独立，这样每一个线程都可以随意修改自己的变量副本，而不会对其他线程产生影响。 

 ThreadLocal 类的常用方法:

- ThreadLocal() : 创建一个线程本地变量 
- get() : 返回此线程局部变量的当前线程副本中的值 
- initialValue() : 返回此线程局部变量的当前线程的"初始值" 
- set(T value) : 将此线程局部变量的当前线程副本中的值设置为value

**采用以"空间换时间"的方法**



##### 4.2.6 使用阻塞队列 

前面5种同步方式都是在底层实现的线程同步，但是我们在实际开发当中，应当尽量远离底层结构。  

常用LinkedBlockingQueue() 。



##### 4.2.7 AtomicInteger 

使用原子变量实现线程同步 

原子操作就是指将读取变量值、修改变量值、保存变量值看成一个整体来操作即-这几种行为要么同时完成，要么都不完成。

在java的util.concurrent.atomic包中提供了创建了原子类型变量的工具类，使用该类可以简化线程同步。其中AtomicInteger 表可以用原子方式更新int的值，可用在应用程序中(如以原子方式增加的计数器)，但不能用于替换Integer；可扩展Number，允许那些处理机遇数字类的工具和实用工具进行统一访问。




# 5 进程同步有哪几种机制 

原子操作、信号量机制、自旋锁、管程、会合、分布式系统 

### 5.1 信号量机制

什么是信号量？信号量（semaphore）的数据结构为一个值和一个指针，指针指向等待该信号量的下一个进程。信号量的值与相应资源的使用情况有关。

- 当它的值大于0时，表示当前可用资源的数量；
- 当它的值小于0时，其绝对值表示等待使用该资源的进程个数。

一个信号量只能置一次初值，以后只能对之进行p操作或v操作。 由此也可以看到，信号量机制必须有公共内存，不能用于分布式操作系统，这是它最大的弱点。  



### 5.2 原子操作

[博客](https://www.cnblogs.com/fanzhidongyzby/p/3654855.html)

C语言语句“count++;”在未经编译器优化时生成的汇编代码为：

![](../assets/1.16.jpg)

当操作系统内存在多个进程同时执行这段代码时，就可能带来并发问题。 

假设count变量初始值为0。进程1执行完“mov eax, [count]”后，寄存器eax内保存了count的值0。此时，进程2被调度执行，抢占了进程1的CPU的控制权。进程2执行“count++;”的汇编代码，将累加后的count值1写回到内存。然后，进程1再次被调度执行，CPU控制权回到进程1。进程1接着执行，计算count的累加值仍为1，写回到内存。虽然进程1和进程2执行了两次“count++;”操作，但是count实际的内存值为1，而不是2！ 



##### 5.2.1 单处理器原子操作

解决这个问题的方法是，将“count++;”语句翻译为单指令操作。 

![](../assets/1.17.jpg)





##### 5.2.2 多处理器原子操作

但是在多处理器的环境下，例如SMP架构，这个结论不再成立。我们知道“inc [count]”指令的执行过程分为三步：

1）从内存将count的数据读取到cpu。

2）累加读取的值。

3）将修改的值写回count内存。

于是Intel x86指令集提供了指令前缀lock用于锁定前端串行总线（FSB），保证了指令执行时不会受到其他处理器的干扰。 

![](../assets/1.18.jpg)

使用lock指令前缀后，处理器间对count内存的并发访问（读/写）被禁止，从而保证了指令的原子性。 





### 5.3 自旋锁

基于原子操作，nginx实现了一个自旋锁。自旋锁是为了保护共享资源提出的一种锁机制。 自旋锁是一种非睡眠锁。调用者申请的资源如果被占用，即自旋锁被已经被别的执行单元保持，则调用者一直循环在那里看是否该自旋锁的保持着已经释放了锁，自旋锁是一种比较低级的保护数据结构和代码片段的原始方式，可能会引起以下两个问题;   （1）死锁   （2）过多地占用CPU资源  



**应用场景：**

   自旋锁主要是为多处理器操作系统而设置的，他要解决的共享资源保护场景就是进程使用锁的时间非常短（如果锁的使用时间很久，自旋锁不合适，因为会占用大量的CPU资源）。  

   大部分情况下Nginx的worker进程最好都不要进入睡眠状态，因为它非常繁忙，在这个进程的epoll上可能有十万甚至百万的TCP连接等待着处理，进程一旦睡眠后必须等待其他事件的唤醒，这中间及其频繁的进程间切换带来的负载消耗可能无法让用户接受。  



### 5.4 管程

[博客](https://www.cnblogs.com/yongh/p/9294838.html)

在信号量机制中，每个要访问临界资源的进程都必须自备同步的PV操作，大量分散的同步操作会给系统管理带来麻烦，且容易因为同步操作不当而导致系统死锁。于是便产生了一种新的进程同步工具——**管程（Monitors）**。

**管程（Monitors）：**是一个资源管理模块，其中包含了共享资源的数据结构，以及由对该共享数据结构实施操作的一组过程（方法）所组成的资源管理程序。

管程中包含**条件变量**，用于管理进程的阻塞和唤醒。其形式为 condition x；对它的操作仅有wait和signal。

- **x.wait**：正在调用管程的进程因 x 条件需要被阻塞或挂起，则调用 x.wait 将自己插入到 x 条件的等待队列上，并释放管程，直到 x 条件变化。此时其它进程可以使用该管程。
- **x.signal**：正在调用管程的进程发现 x 条件发生了变化，则调用 x.signal，重新启动一个因 x 条件而阻塞或挂起的进程。（与信号量的signal不同，没有s:=s+1的操作）

 

**java中的管程：**

Java 采用的是管程技术，synchronized 关键字及 wait()、notify()、notifyAll() 这三个方法都是管程的组成部分。而**管程和信号量是等价的，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程**。但是**管程利用OOP的封装特性解决了信号量在工程实践上的复杂性问题**，因此java采用管理机制。 



**总结：**

1. 管程相当于把对临界资源的操作封装了起来，当进程要对资源进行操作时，只要调用管程中的方法就可以了，而不用进程自己担心同步和互斥的问题，管程的内部有自己的一套机制进行同步与互斥。
2. 管程中每次只允许一个进程进入管程。
3. 当调用管程的进程因为某原因阻塞或者挂起时，把这个原因定义为一个条件变量x。
4. x.wait操作就是把自己放到一个队列上，这个队列上的进程都是因为x原因而阻塞的。
5. x.signal操作就是让在x阻塞队列上的一个进程重新启动。

> **相对形象的比喻**：假如一个管程叫ATM（取款机），其包含两个方法：存款和取款，不同的人代表不同的进程，但是ATM只允许一个人在一个时间段中进行操作，当一个人在使用时，其他的人只能wait。此外，一个人如果使用的时间太长也不行，所以需要一个条件变量来约束他。
>
> 比如一个人在操作ATM时突然接电话了，没法继续操作，把这个原因记为x，执行x.wait，让他离开ATM机，去接电话的队列中等待。等到打完电话，即调用了x.signal后，他就可以继续操作ATM了（一般令正在操作ATM的人操作完后，他才能重新进去）。

 



### 5.5 会合

管程比PV操作要高级一些，但是和PV操作等价，只适合与单处理器系统及具有公共内存的多处理器系统。 

是适合分布式系统的同步机制。



### 5.6 分布式系统

适合分布式系统的同步机制。





## 6 进程生命周期

就绪状态：进程已获得除处理机以外的所需资源，等待分配处理机资源；

运行状态：占用处理机资源运行，处于此状态的进程数小于等于CPU数；

阻塞状态： 进程等待某种条件，在条件满足之前无法执行；

![](../assets/1.7.jpg)







# 7 页式管理、段式管理和段页式管理(内存管理) 

[博客](https://blog.csdn.net/smilesundream/article/details/70148878)

内存管理方式主要分为：页式管理、段式管理和段页式管理。 

基本存储分配方式：

![](../assets/1.14.png)



### 7.1 页式管理

[博客](https://blog.csdn.net/wang379275614/article/details/13765599?depth_1-utm_source=distribute.pc_relevant.none-task&utm_source=distribute.pc_relevant.none-task)

 页式管理的基本原理是将各进程的虚拟空间划分为若干个长度相等的页。把内存空间按页的大小划分为片或者页面，然后把页式虚拟地址与内存地址建立一一对应的页表，并用相应的硬件地址转换机构来解决离散地址变换问题。页式管理采用请求调页和预调页技术来实现内外存存储器的统一管理。

-  优点：没有外碎片，每个内碎片不超过页的大小。
-  缺点：程序全部装入内存，要求有相应的硬件支持，如地址变换机构缺页中断的产生和选择淘汰页面等都要求有相应的硬件支持。增加了机器成本和系统开销。





### 7.2 段式管理

用户程序**先分段**，每个段内部**再分页（内部原理同基本的分页、分段相同）** 

 段式管理的基本思想是把程序按内容或过程函数关系分成段，每段有自己的名字。一个用户作业或者进程所包含的段对应一个二维线性虚拟空间，也就是一个二维虚拟存储器。段式管理程序以段为单位分配内存，然后通过地址映射机构把段式虚拟地址转换为实际内存物理地址。

-  优点：可以分别编写和编译，可以针对不同类型的段采取不同的保护，可以按段为单位来进行共享，包括通过动态链接进行代码共享。
-  缺点：会产生碎片。



### 7.3  段页式管理

 段页式管理，系统必须为每个作业或者进程建立一张段表以管理内存分配与释放、缺段处理等。另外由于一个段又被划分为若干个页，每个段必须建立一张页表以把段中的虚页变换为内存中的实际页面。显然与页式管理时相同，页表也要有相应的实现缺页中断处理和页面保护等功能的表项。

 段页式管理是段式管理和页式管理相结合而成，具有两者的优点。

由于管理软件的增加，复杂性和开销也增加。另外需要的硬件以及占用的内存也有所增加，使得执行速度下降。





段式存储和页式存储的区别：

- 目的不同：分页是由于系统管理的需要而不是用户的需要，它是信息的物理单位；分段的目的是为了能更好地满足用户的需要，它是信息的逻辑单位，它含有一组其意义相对完整的信息；
- 大小不同：页的大小固定且由系统决定，而段的长度却不固定，由其所完成的功能决定；

- 地址空间不同： 段向用户提供二维地址空间；页向用户提供的是一维地址空间；

- 信息共享：段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制；

- 内存碎片：页式存储管理的优点是没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）；而段式管理的优点是没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）。



# 8 操作系统中进程调度策略

不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。

### 8.1 批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

##### 8.1.1 先来先服务 

> first-come first-serverd（FCFS）  

非抢占式的调度算法，按照请求的顺序进行调度。

有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。



##### 8.1.2 短作业优先 

> shortest job first（SJF）

非抢占式的调度算法，按估计运行时间最短的顺序进行调度。

长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。



##### 8.1.3 最短剩余时间优先

> shortest remaining time next（SRTN）

最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。



### 8.2 交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

##### 8.2.1 时间片轮转

将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和时间片的大小有很大关系：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/8c662999-c16c-481c-9f40-1fdba5bc9167.png"/> </div><br>



##### 8.2.2 优先级调度  

为每个进程分配一个优先级，按优先级进行调度。

为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。



##### 8.2.3 多级反馈队列  

设置多个就绪队列。在系统中设置多个就绪队列，并为每个队列赋予不同的优先。第一个队列的优先级最高，第二个次之，其余队列的优先级逐个降低。该算法为不同列中的进程所赋予的执行时间片的大小也各不相同，在优先级愈高的队列中，其时间片愈小。

每个队列都采用FCFS算法。当新进程进入内存后，首先将它放入第一队列的末尾，按FCFS原则等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可撤离系统。　按队列优先级调度。调度程序首先调度最高优先级队列中的诸进程运行，仅当第一队列空闲时才调度第二队列中的进程运行; 

可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

<div align="center"> <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/042cf928-3c8e-4815-ae9c-f2780202c68f.png"/> </div><br>

### 8.3 实时系统

实时系统要求一个请求在一个确定时间内得到响应。

分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。







# 9 内存&虚拟内存 

### 11.1 内存 

[博客](https://www.cnblogs.com/jmsjh/p/7811601.html)

##### 11.1.1 为什么需要内存

程序和数据平常存储在硬盘等存储器上，不管你开机或关机了，它们都是存在的，不会丢失。硬盘可以存储的东西很多，但其传输数据的速度较慢。所以需要运行程序或打开数据时，这些数据必须从硬盘等存储器上先传到另一种容量小但速度快得多的存储器，之后才送入CPU进行执行处理。这中间的存储器就是内存。 

![](../assets/1.8.png)



**读一个磁盘扇区的流程：**

> 1. CPU 将相关的命令和地址，通过系统总线和IO总线传递给磁盘，发起一个磁盘读。
> 2. 磁盘控制器将相关的地址解析，并通过IO总线与内存总线将数据传给内存。
> 3. 第2步完成之后，磁盘控制器向CPU发送一个中断信号。(学电子的同学应该很清楚中断是什么)。这时CPU就知道了，数据已经发送到内存了。

第二步磁盘操作很慢，但是在第一步CPU发出信号后。但是第二步和第三步时，CPU根本不参与。第二步很耗时，所以CPU在第一步发出信号后，就切换到另一个线程。所以此时的CPU依旧没有闲着。而在第三步时，通过中断，硬盘主动发信号给CPU，你需要的数据已经发送到内存了，然后此时它可以将线程再切换回来，接着执行这个该线程的任务。 





### 11.2 虚拟内存

[博客1](https://www.cnblogs.com/jmsjh/p/8017202.html)

[博客2](https://www.cnblogs.com/logo-fox/p/10843348.html)

##### 11.2.1 虚拟内存（windows）

**定义：虚拟内存其实就是将一部分硬盘空间划分出来当做内存来使用，放在内存读取顺序的最末端优先度上，应用程序认为自己是在一个连续完整的物理内存空间上，而实际上该程序已经被分割成为多个物理内存的碎片，一部分碎片被存放在虚拟内存也就是硬盘的预留空间上，在将要被使用时这部分数据被重新提取到内存中，于是呈现出一种内存大小提高的假象，提高运行速度。在linux上同样也存在这个功能，只不过它的名字不叫虚拟内存，而是叫做“交换空间swap分区” **



##### 11.2.2 swap分区（linux）

熟悉linux的同学，应该知道**linux有一个swap分区**。Swap空间的作用可简单描述为：当系统的物理内存不够用的时候，就需要将物理内存中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间中的信息被临时保存到Swap空间中，等到那些程序要运行时，再从Swap中恢复保存的数据到内存中。系统总是在物理内存不够时，才进行Swap交换。

> 你电脑打开了一个音乐播放器，但是也没播放歌曲，然后你几天不关机，也一直没关闭这个音乐播放器，随着运行的程序越来越多，内存快不够用了，所以操作系统就选择将这个音乐播放器的内存状态(包括堆栈状态等)都写到磁盘上的swap区进行保存。这样就腾出来一部分内存供其他需要运行的程序使用。你啥时候想听歌了，就找到了这个音乐播放器程序操作。此时，  系统会从磁盘中的swap区重新读取该音乐播放器的相关信息，送回内存接着运行。

在window下也有类作用的硬盘空间，属于对用户不可见的匿名磁盘空间(在C盘)。



# 12 协程

[博客1](https://www.zhihu.com/question/20511233)

[博客2](https://blog.csdn.net/zheng199172/article/details/88800275)



![](../assets/1.21.jpeg)



**协程不是被操作系统内核所管理的，而是完全由程序所控制，也就是在用户态执行。这样带来的好处是性能大幅度的提升，因为不会像线程切换那样消耗资源。**

协程不是进程也不是线程，而是一个特殊的函数，这个函数可以在某个地方挂起，并且可以重新在挂起处外继续运行。所以说，协程与进程、线程相比并不是一个维度的概念。

一个进程可以包含多个线程，一**个线程也可以包含多个协程**。简单来说，一个线程内可以由多个这样的特殊函数在运行，但是有一点必须明确的是，一个线程的多个协程的运行是串行的。如果是多核CPU，多个进程或一个进程内的多个线程是可以并行运行的，但是一个线程内协程却绝对是串行的，无论CPU有多少个核。毕竟协程虽然是一个特殊的函数，但仍然是一个函数。一个线程内可以运行多个函数，但这些函数都是串行运行的。当一个协程运行时，其它协程必须挂起。

**进程、线程、协程的对比**

- 协程既不是进程也不是线程，协程仅仅是一个特殊的函数，协程它进程和进程不是一个维度的。
- 一个进程可以包含多个线程，一个线程可以包含多个协程。
- 一个线程内的多个协程虽然可以切换，但是多个协程是串行执行的，只能在一个线程内运行，没法利用CPU多核能力。
- 协程与进程一样，切换是存在上下文切换问题的。

**上下文切换**

- 进程的切换者是操作系统，切换时机是根据操作系统自己的切换策略，用户是无感知的。进程的切换内容包括页全局目录、内核栈、硬件上下文，切换内容保存在内存中。进程切换过程是由“用户态到内核态到用户态”的方式，切换效率低。
- 线程的切换者是操作系统，切换时机是根据操作系统自己的切换策略，用户无感知。线程的切换内容包括内核栈和硬件上下文。线程切换内容保存在内核栈中。线程切换过程是由“用户态到内核态到用户态”， 切换效率中等。
- **协程的切换者是用户（编程者或应用程序），切换时机是用户自己的程序所决定的。协程的切换内容是硬件上下文，切换内存保存在用户自己的变量（用户栈或堆）中。协程的切换过程只有用户态，即没有陷入内核态，因此切换效率高。**

 

 



**首先看一个典型生产者和消费者的问题：（代码不贴了）**

1. 定义了一个生产者类，一个消费者类。
2. 生产者类循环100次，向同步队列当中插入数据。
3. 消费者循环监听同步队列，当队列有数据时拉取数据。
4. 如果队列满了（达到5个元素），生产者阻塞。
5. 如果队列空了，消费者阻塞。

上面的过程正确地实现了生产者/消费者模式，但是却并不是一个高性能的实现。为什么性能不高呢？原因如下：

1. 涉及到同步锁。
2. 涉及到线程阻塞状态和可运行状态之间的切换。
3. 涉及到线程上下文的切换。

**以上涉及到的任何一点，都是非常耗费性能的操作。**

**如果用协程，可以完美地避免上面三个问题，因为协程不需要进行线程的切换，所以它的资源不需要竞争，也不涉及同步锁。**



**协程的适用场景：当程序中存在大量不需要CPU的操作时（IO），适用于协程；**

```python
import time

def consumer():
    r = ''
    while True:
        n = yield r	#consumer通过yield拿到消息，处理，又通过yield把结果传回
        if not n:
            return
        print('[CONSUMER] Consuming %s...' % n)
        time.sleep(1)
        r = '200 OK'

def produce(c):
    c.next()   #调用c.next()启动生成器
    n = 0
    while n < 5:
        n = n + 1
        print('[PRODUCER] Producing %s...' % n)
        r = c.send(n)   #一旦生产了东西，通过c.send(n)切换到consumer执行
        print('[PRODUCER] Consumer return: %s' % r)  #produce拿到consumer处理的结果，继续生产下一条消息；
    c.close()

if __name__=='__main__':
    c = consumer()
    produce(c)
```

执行结果：

```python
[PRODUCER] Producing 1...
[CONSUMER] Consuming 1...
[PRODUCER] Consumer return: 200 OK
[PRODUCER] Producing 2...
[CONSUMER] Consuming 2...
[PRODUCER] Consumer return: 200 OK
[PRODUCER] Producing 3...
[CONSUMER] Consuming 3...
[PRODUCER] Consumer return: 200 OK
[PRODUCER] Producing 4...
[CONSUMER] Consuming 4...
[PRODUCER] Consumer return: 200 OK
[PRODUCER] Producing 5...
[CONSUMER] Consuming 5...
[PRODUCER] Consumer return: 200 OK
```

注意到consumer函数是一个generator（生成器），把一个consumer传入produce后：

1. 首先调用c.next()启动生成器；
2. 然后，一旦生产了东西，通过c.send(n)切换到consumer执行；
3. consumer通过yield拿到消息，处理，又通过yield把结果传回；
4. produce拿到consumer处理的结果，继续生产下一条消息；
5. produce决定不生产了，通过c.close()关闭consumer，整个过程结束。

整个流程无锁，由一个线程执行，produce和consumer协作完成任务，所以称为“协程”，而不是线程的抢占式多任务。





# 13 用户态和核心态

[博客](https://blog.csdn.net/qq_39823627/article/details/78736650)

### 13.1 特权级的概念

对于任何操作系统来说，创建一个进程是核心功能。创建进程要做很多工作，会消耗很多物理资源。比如分配物理内存，父子进程拷贝信息，拷贝设置页目录页表等等，这些工作得由特定的进程去做，所以就有了特权级别的概念。

最关键的工作必须交给特权级最高的进程去执行，这样可以做到集中管理，减少有限资源的访问和使用冲突。且低优先级的进程不能操作高优先级的进程的数据，具有一定的安全保护作用。

inter x86架构的cpu一共有四个级别，0-3级，0级特权级最高（内核态），3级特权级最低（用户态）。



### 13.2 用户态和内核态的概念 

**用户态：**当一个进程在执行用户自己的代码时处于用户运行态（用户态），此时特权级最低，为3级。Ring3状态不能访问Ring0的地址空间，包括代码和数据；当一个进程因为系统调用陷入内核代码中执行时处于内核运行态（内核态），此时特权级最高，为0级。执行的内核代码会使用当前进程的内核栈，每个进程都有自己的内核栈。

**内核态：**如果要执行文件操作、网络数据发送等操作必须通过write、send等系统调用，这些系统调用会调用内核的代码。进程会切换到Ring0，然后进入3G-4G中的内核地址空间去执行内核代码来完成相应的操作。内核态的进程执行完后又会切换到Ring3，回到用户态。





### 13.3 用户态和内核态的切换 

当在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成一些用户态自己没有特权和能力完成的操作时就会切换到内核态。

用户态切换到内核态的3种方式：

1. **系统调用**

   这是用户态进程主动要求切换到内核态的一种方式。用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。例如fork（）就是执行了一个创建新进程的系统调用。系统调用的机制和新是使用了操作系统为用户特别开放的一个中断来实现，如Linux的int 80h中断。

2. **异常**

   当cpu在执行运行在用户态下的程序时，发生了一些没有预知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关进程中，也就是切换到了内核态，如缺页异常。

3. **外围设备的中断**

   当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令而转到与中断信号对应的处理程序去执行，如果前面执行的指令是用户态下的程序，那么转换的过程自然就会是 由用户态到内核态的切换。如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后边的操作等。

这三种方式是系统在运行时由用户态切换到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。**系统调用实际上最终是中断机制实现的，而异常和中断的处理机制基本一致。**



　　注意：系统调用的本质其实也是中断，相对于外围设备的硬中断，这种中断称为软中断，这是操作系统为用户特别开放的一种中断，如Linux int 80h中断。所以，从触发方式和效果上来看，这三种切换方式是完全一样的，都相当于是执行了一个中断响应的过程。但是从触发的对象来看，系统调用是进程主动请求切换的，而异常和硬中断则是被动的。





# 14 中断

如果让内核定期对设备进行轮询，以便处理设备，那会做很多无用功，因为外设的处理速度一般慢于CPU，而CPU不能一直等待外部事件。所以能让**设备在需要内核时主动通知内核，会是一个聪明的方式，这便是中断。**

[博客](https://blog.csdn.net/ypshowm/article/details/89174951)

中断是指CPU对系统发生的某个事件做出的一种反应，CPU暂停正在执行的程序，保存现场后自动去执行相应的处理程序，处理完该事件后再返回中断处继续执行原来的程序。



### 14.1 中断类型 

中断一般三类：

- **外中断：**由CPU外部引起

  如`I/O中断`，表示设备输入/输出处理已经完成，希望处理机能够向设备发下一个输入 / 输出请求，同时让完成输入/输出后的程序继续运行。

  `时钟中断`，表示一个固定的时间片已到，让处理机处理计时、启动定时运行的任务等。

  这一类中断通常是与当前程序运行无关的事件，即它们与当前处理机运行的程序无关。

- **内中断：**由CPU内部事件或程序执行中引起，例如程序非法操作，地址越界、浮点溢出，或者异常

- 系统调用：系统调用就是用户在程序中调用操作系统所提供的一些子功能。系统中的各种共享资源都由操作系统统一掌管，因此在用户程序中，凡是与资源有关的操作（如存储分配、进行I/0传输以及管理文件等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。



### 14.2 中断处理方式

##### 14.2.1 屏蔽（禁止）中断

当处理机正在处理一个中断时，将屏蔽掉所有的中断，直到处理机已完成本次中断的处理后，处理机再去检查是否有中断发生。所有中断都按顺序依次执行，优点是简单，不适合用于对实时性要求较高的中断请求。



##### 14.2.2 **嵌套中断** 

在设置了中断优先级的系统中。通常按这样的规则来处理中断。

1. 当同时有多个不同优先级的中断请求时，CPU优先响应最高优先级的中断请求。
2. 高优先级的中断请求可以抢占正在运行的低优先级中断的处理机。



**中断处理程序的处理过程**

1. 测定是否有未响应的中断信号。
2. 保护被中断进程的CPU环境。
3. 转入相应的设备处理程序。
4. 中断处理。
5. 恢复CPU的现场并退出中断。





# （下次再看）14 操作系统分配的进程空间是怎样的？线程能共享哪些？  

 **进程是由程序控制块（PCB）、程序段、数据段组成。**

 操作系统是通过PCB来管理进程，因此PCB中应该包含操作系统对其进行管理所需的各种信息，如进程描述信息、进程控制和管理信息、资源分配清单和处理机相关信息。

程序段：程序代码存放的位置。

数据段：程序运行时使用、产生的运算数据。如全局变量、局部变量、宏定义的常量就存放在数据段内。

 

![](../assets/1.23.png)



https://www.jianshu.com/p/583334385b41







# 15 页面置换算法

> 缺页中断缺页中断:每当所要访问的页面不在内存时，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。  

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。

页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

### 15.1 Optimal算法-最优算法 

> Optimal replacement algorithm

所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。

**是一种理论上的算法，无法被实现，因为无法知道一个页面多长时间不再被访问。**

举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列：

```html
7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1
```

开始运行时，先将 7, 0, 1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。





### 15.2 FIFO-先进先出

选择换出的页面是最先进入的页面。

**缺点：**该算法会将那些经常被访问的页面也被换出，从而使缺页率升高。



**改进1：（第二次机会）算法 **

FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：

- 当选择置换页面时，检查它的访问位。如果是0，就淘汰这页；如果访问位是1，就给它第二次机会，并选择下一个FIFO页面。
- 当一个页面得到第二次机会时，它被放到链表最后，同时它的访问位被清为0，它的到达时间就置为当前时间。如果该页在此期间被访问过，则访问位置1。这样给了第二次机会的页面将不被淘汰，直至所有其他页面被淘汰过（或者也给了第二次机会）。因此，如果一个页面经常使用，它的访问位总保持为1，它就从来不会被淘汰出去。 



<img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/ecf8ad5d-5403-48b9-b6e7-f2e20ffe8fca.png"/>



**改进2：Clock算法（时钟轮转法） **

第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用**环形链表**将页面连接起来，这样**每一次进行替换指针的位置就从替换数移到下一个位置,每一次进行访问时，则指针保持不动。** 

这样只需要移动指针，页面就自动到了环形链表的最后位置，无需移动页面。

 <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/5f5ef0b6-98ea-497c-a007-f6c55288eab1.png"/> 







### 15.3 LRU-最近最久未使用

>  Least Recently Used

LRU 将最近最久未使用的页面换出。

为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

> 4，7，0，7，1，0，1，2，1，2，6

 <img src="https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/eb859228-c0f2-4bce-910d-d9f76929352b.png"/>



手写LRU（代码）：

```java

public class LRUList<T> {

    private static final int DEFAULT_SIZE = 10;
    private int capacity;
    private Node<T> head;
    private Node<T> tail;
    private int size;

    public LRUList() {
        this(DEFAULT_SIZE);
    }

    public LRUList(int capacity) {
        this.capacity = capacity;
    }

    /**
     * 访问元素 t
     * -查询数据
     * --存在 - 在头部则返回  - 不在头部，移动到头部（是否是结尾）
     * --不存在 添加数据-添加到头部
     * ---是否达到capacity -是 移除尾部数据 -否 ¬不移除
     *
     * @param t 元素
     */
    public void access(T t) {
        int index = indexOfElement(t);
        if (index != -1) {
            if (index == 0) {
                return;
            } else {
                moveToHead(index);
            }
        } else {
            addElement(t);
        }
    }

    /**
     * 添加元素到头部
     *
     * @param t 元素
     */
    private void addElement(T t) {
        Node<T> node = new Node<>(t);
        if (size == capacity) {
            removeLast();
        }
        Node<T> f = head;
        node.prev = null;
        node.next = head;
        head = node;
        if (f == null) {
            tail = node;
        } else {
            f.prev = node;
        }
        size++;
    }

    /**
     * 移除最后一个节点
     */
    private void removeLast() {
        if (isEmpty()) {
            return;
        }
        Node<T> l = tail;
        tail = tail.prev;
        if (tail == null) {
            head = null;
        } else {
            tail.next = null;
        }
        l.prev = null;
        l.item = null;
        size--;
    }

    /**
     * 将元素移动到头部
     *
     * @param index 索引
     */
    private void moveToHead(int index) {
        Node<T> node;
        if (index == size - 1) {
            node = tail;
            tail = tail.prev;
            tail.next = null;
        } else {
            node = getNodeByIndex(index);
            node.prev.next = node.next;
            node.next.prev = node.prev;
        }
        node.prev = null;
        node.next = head;
        head.prev = node;
        head = node;
    }

    /**
     * 根据索引获取节点
     *
     * @param index 索引
     * @return 节点
     */
    private Node<T> getNodeByIndex(int index) {
        if (index < 0 || index >= size) {
            throw new IndexOutOfBoundsException("index out of bounds");
        }
        Node<T> node = head;
        for (int i = 0; i < index; i++) {
            node = node.next;
        }
        return node;
    }

    /**
     * 查找节点索引
     *
     * @param t 元素
     * @return 不考虑为空的元素
     */
    private int indexOfElement(T t) {
        if (isEmpty()) {
            return -1;
        }
        int index = 0;
        for (Node node = head; node != null; node = node.next) {
            if (node.item.equals(t)) {
                return index;
            }
            index++;
        }
        return -1;
    }

    public boolean isEmpty() {
        return size == 0;
    }

    @Override
    public String toString() {
        if (isEmpty()) {
            return "[]";
        }
        StringBuilder builder = new StringBuilder();
        for (Node<T> node = head; node != null; node = node.next) {
            builder.append(node.item.toString()).append(",");
        }
        String result = builder.toString();
        return result.substring(0, result.length() - 1);
    }

    private static class Node<T> {
        private Node<T> prev;
        private Node<T> next;
        private T item;

        public Node(T item) {
            this.item = item;
        }
    }
}

```



测试：

```java
public class LRUListTest {

    @Test
    public void test() {

        LRUList<Integer> frame = new LRUList<>(3);
        frame.access(7);
        frame.access(0);
        frame.access(1);
        Assert.assertEquals("1,0,7", frame.toString());
        frame.access(2);
        Assert.assertEquals("2,1,0", frame.toString());
        frame.access(0);

        Assert.assertEquals("0,2,1", frame.toString());

        frame.access(0);
        Assert.assertEquals("0,2,1", frame.toString());
        frame.access(3);
        Assert.assertEquals("3,0,2", frame.toString());
        frame.access(0);
        Assert.assertEquals("0,3,2", frame.toString());
        frame.access(4);
        Assert.assertEquals("4,0,3", frame.toString());
    }
}

```







